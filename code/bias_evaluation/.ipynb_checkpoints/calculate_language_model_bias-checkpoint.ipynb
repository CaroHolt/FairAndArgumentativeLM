{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-sauce",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "green-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of adapters\n",
    "all_adapters_dir = '../../results/'\n",
    "# Create empty list to append results of all models\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-oklahoma",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-paragraph",
   "metadata": {},
   "source": [
    "## Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generic-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/helper_functions.py\n",
    "%run ../utils/target_terms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-hurricane",
   "metadata": {},
   "source": [
    "## Function to prepare data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(annotation_frame_dir, target_term_dir):\n",
    "    \"\"\"Prepare the DataFrames for the specific bias types to contain the biased and inversly biased sentences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    annotation_frame_dir : str\n",
    "        Directory to the annotated DataFrame.\n",
    "    target_term_dir : str\n",
    "        Directory to the target term pairs of the respective bias type.         \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        \n",
    "    \"\"\"\n",
    "    # Load Annotation data\n",
    "    df = pd.read_excel(annotation_frame_dir)   \n",
    "    \n",
    "    # Only keep biased sentences\n",
    "    df = df[df['Biased Sentence'] == 1]\n",
    "\n",
    "    # Only keep relevant columns\n",
    "    df = df[['Column1', 'ID','newSent']]\n",
    "\n",
    "    # Print the number of biased sentences for all biased attribute terms\n",
    "    print(\"Number of biased sentences per Attribute: \" + str(len(df)))\n",
    "\n",
    "    # Rename Sentence column\n",
    "    df = df.rename(columns={'newSent': 'Biased Sentence'})\n",
    "\n",
    "    # Lowercase biased sentences\n",
    "    df['Biased Sentence'] = df.apply(lambda row: row['Biased Sentence'].lower(), axis = 1)\n",
    "\n",
    "    # Drop duplicate sentences\n",
    "    df = df.drop_duplicates(subset=['Biased Sentence'])\n",
    "    \n",
    "    # Number of rows found per target term in sentence\n",
    "    print(\"Number of biased sentences without duplicates: \" + str(len(df)))\n",
    "    \n",
    "    # Merge Target Terms\n",
    "    # Retrieve Target Term list\n",
    "    target_term_pairs = pd.read_csv(target_term_dir)\n",
    "\n",
    "    #Create list of all target terms\n",
    "    target_terms = list(set(target_term_pairs['T1'].tolist())) + list(set(target_term_pairs['T2'].tolist()))\n",
    "\n",
    "    # Find target terms in biased sentence\n",
    "    df['tt_list'] = df.apply(lambda row: findTargetTerms(row['Biased Sentence'], target_terms), axis = 1)\n",
    "\n",
    "    # Find matching opposite target term\n",
    "    df['tt_opp_list'] = df.apply(lambda row: findOppositeTargetTerm(row['tt_list'], target_term_pairs), axis = 1)\n",
    "    \n",
    "    # Apply CDA\n",
    "    # Create Combination of target terms and their opposite terms\n",
    "    df['Target Term Combination'] = df.apply(lambda row: createCombination(row), axis = 1)\n",
    "\n",
    "    # Create all possible Opposing Sentences\n",
    "    df['Opposing Sentence'] = df.apply(lambda row: replaceTermsInSentence(row), axis = 1)\n",
    "    \n",
    "    print(\"Dataframe prepared!\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-gates",
   "metadata": {},
   "source": [
    "# Function to calculate Model Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ancient-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePerplexity(model_name, \n",
    "                        test_df,\n",
    "                        bias_type,\n",
    "                        adapter_dir1 = None,\n",
    "                        adapter_dir2 = None):\n",
    "    \"\"\"Calculates the perplexity for a sentence given a certain model and the pretrained adapter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The name of the pre-trained model that should be used.\n",
    "        To reproduce the thesis one can decide between: \n",
    "            - bert-base-uncased\n",
    "            - roberta-base\n",
    "            - gpt2\n",
    "            - microsoft/DialoGPT-medium    \n",
    "    bias_type : str\n",
    "        Bias type that should be evaluated. Choose between:\n",
    "            - Islamophobia\n",
    "            - Queerphobia\n",
    "    test_df : Data Frame\n",
    "        Test dataframe containing the biased and augmented inversely biased sentences\n",
    "    adapter_dir1 : str\n",
    "        Name of directory where trained argumentative or debiasing adapter is stored.\n",
    "    adapter_dir2 : str\n",
    "        Name of directory where the second trained argumentative or debiasing adapter is stored.\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        consisting of:\n",
    "        - Model Name\n",
    "        - Fine Tuning Dataset\n",
    "        - Mean PPL BS\n",
    "        - Mean PPL OS\n",
    "        - t-value\n",
    "        - p-value\n",
    "    \"\"\"\n",
    "    if 'bert' in model_name:\n",
    "        language_model = 'BERT'\n",
    "        model_type = 'mlm'\n",
    "    elif 'gpt2' in model_name:\n",
    "        language_model = 'GPT-2'\n",
    "        model_type = 'clm'\n",
    "    else:\n",
    "        raise InputError('Model type is not recognized.')\n",
    "        \n",
    "    if adapter_dir1:\n",
    "        if 'argsme' in adapter_dir1:\n",
    "            strategy = 'Args.me'\n",
    "        elif 'wiki' in adapter_dir1:\n",
    "            strategy = 'Wikipedia'\n",
    "    elif adapter_dir1 & adapter_dir2:\n",
    "        strategy = 'stacking'\n",
    "    else:\n",
    "        strategy = 'original'\n",
    "    \n",
    "    \n",
    "    print('Evaluate Results for ' + language_model + ' on ' + strategy + ' Corpora concerning ' + bias_type)\n",
    "    # Load pre-trained model (weights)\n",
    "    print('Load trained model.....')\n",
    "    if model_type == 'mlm':\n",
    "        with torch.no_grad():\n",
    "            model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "            if strategy == 'stacking':\n",
    "                model.load_adapter(all_adapters_dir + adapter_dir1 + '/mlm', load_as='model_adapter1', with_head=False)\n",
    "                model.load_adapter(all_adapters_dir + adapter_dir2 + '/mlm', load_as='model_adapter2', with_head=False)\n",
    "                model.active_adapters = ac.Stack('model_adapter1', 'model_adapter2')\n",
    "            elif strategy == 'Args.me' or strategy == 'Wikipedia':\n",
    "                model.load_adapter(all_adapters_dir + adapter_dir1 + '/mlm', load_as='model_adapter')\n",
    "                model.set_active_adapters('model_adapter')\n",
    "    elif model_type == 'clm':\n",
    "        with torch.no_grad():\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "            if strategy == 'stacking':\n",
    "                model.load_adapter(all_adapters_dir + adapter_dir1 + '/clm', load_as='model_adapter1', with_head=False)\n",
    "                model.load_adapter(all_adapters_dir + adapter_dir2 + '/clm', load_as='model_adapter2', with_head=False)\n",
    "                model.active_adapters = ac.Stack('model_adapter1', 'model_adapter2')\n",
    "            elif strategy == 'Args.me' or strategy == 'Wikipedia':\n",
    "                model.load_adapter(all_adapters_dir + adapter_dir1 + '/mlm', load_as='model_adapter')\n",
    "                model.set_active_adapters('model_adapter')\n",
    "    else:\n",
    "        raise InputError('Model type is not recognized.')\n",
    "    print('Model loaded successfully!')\n",
    "\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Calculate perplexity score of biased sentences\n",
    "    print('Calculate Perplexity Scores.....')\n",
    "    biased_sentences =  test_df['Biased Sentence'].tolist()\n",
    "    inversely_biased_sentences =  test_df['Opposing Sentence'].tolist()\n",
    "    pps_biased_sents = []\n",
    "    for biased_sent in tqdm(biased_sentences):\n",
    "        if model_type == 'mlm':\n",
    "            tokenize_input = tokenizer.tokenize(biased_sent)\n",
    "            tokenize_input = [\"[CLS]\"]+tokenize_input+[\"[SEP]\"]\n",
    "            tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "        elif model_type == 'clm':\n",
    "            tokenize_input = tokenizer.tokenize(biased_sent)\n",
    "            tensor_input = torch.tensor([ [50256]  +  tokenizer.convert_tokens_to_ids(tokenize_input) + [50256]])\n",
    "        loss = model(tensor_input, labels=tensor_input)[0]\n",
    "        pps_biased_sents.append(np.exp(loss.detach().numpy()))\n",
    "\n",
    "    # Calculate perplexity score of oppositely biased sentences    \n",
    "    pps_opp_biased_sents = []\n",
    "    for opp_biased_sents in tqdm(inversely_biased_sentences):\n",
    "        tmp = []\n",
    "        for opp_biased_sent in opp_biased_sents:\n",
    "            if model_type == 'mlm':\n",
    "                tokenize_input = tokenizer.tokenize(opp_biased_sent)\n",
    "                tokenize_input = [\"[CLS]\"]+tokenize_input+[\"[SEP]\"]\n",
    "                tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "            elif model_type == 'clm':\n",
    "                tokenize_input = tokenizer.tokenize(opp_biased_sent)\n",
    "                tensor_input = torch.tensor([ [50256]  +  tokenizer.convert_tokens_to_ids(tokenize_input) + [50256]])\n",
    "            loss = model(tensor_input, labels=tensor_input)[0]   \n",
    "            tmp.append(np.exp(loss.detach().numpy()))\n",
    "        tmp_mean = sum(tmp) / len(tmp)\n",
    "        pps_opp_biased_sents.append(tmp_mean)\n",
    "    print('Perplexity Scores calculated successfully!')\n",
    "    \n",
    "    ttest,pval,num_samples,mean_bs,mean_os = t_test(pps_biased_sents, pps_opp_biased_sents)\n",
    "    \n",
    "    result = {\"Model\": language_model,\n",
    "              \"Bias Type\": bias_type,\n",
    "              \"Strategy\": strategy,\n",
    "              \"Mean PPL BS\": mean_bs, \n",
    "              \"Mean PPL OS\": mean_os, \n",
    "              \"t-value\": ttest, \n",
    "              \"p-value\": pval}\n",
    "\n",
    "    all_results.append(result)\n",
    "    \n",
    "    from tabulate import tabulate\n",
    "    print(\"Paired t-test of \" + language_model)\n",
    "    print(tabulate([['Sample size', num_samples], \n",
    "                    ['Mean PPL BS', mean_bs],\n",
    "                    ['Mean PPL OS', mean_os],\n",
    "                    ['Difference Mean', mean_bs-mean_os],\n",
    "                    ['t-value', ttest],\n",
    "                    ['P-value (two-tail)', pval],\n",
    "                   ]))  \n",
    "\n",
    "    return pd.DataFrame([result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-canadian",
   "metadata": {},
   "source": [
    "# Prepare Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biased sentences per Attribute: 358\n",
      "Number of biased sentences without duplicates: 280\n",
      "Dataframe prepared!\n",
      "Number of biased sentences per Attribute: 648\n",
      "Number of biased sentences without duplicates: 465\n",
      "Dataframe prepared!\n"
     ]
    }
   ],
   "source": [
    "df_queerphobia_bias = prepare_df('../../data/ABBA/abba_queerphobia_annotations.xlsx',\n",
    "                               '../../data/target_term_pairs/target_term_pairs_queerphobia_bias.csv')\n",
    "\n",
    "df_islamophobia_bias = prepare_df('../../data/ABBA/abba_islamophobia_annotations.xlsx',\n",
    "                               '../../data/target_term_pairs/target_term_pairs_islamophobia_bias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-calvin",
   "metadata": {},
   "source": [
    "# Calculate Perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "standing-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Results for BERT on Args.me Corpora concerning Queerness Bias\n",
      "Load trained model.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Perplexity Scores.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 280/280 [00:42<00:00,  6.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 280/280 [02:30<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Scores calculated successfully!\n",
      "Paired t-test of BERT\n",
      "------------------  -----------\n",
      "Sample size         273\n",
      "Mean PPL BS           7.67311\n",
      "Mean PPL OS           7.39309\n",
      "Difference Mean       0.280018\n",
      "t-value               2.30089\n",
      "P-value (two-tail)    0.0221545\n",
      "------------------  -----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Bias Type</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Mean PPL BS</th>\n",
       "      <th>Mean PPL OS</th>\n",
       "      <th>t-value</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>Queerness Bias</td>\n",
       "      <td>Args.me</td>\n",
       "      <td>7.67311</td>\n",
       "      <td>7.393092</td>\n",
       "      <td>2.300889</td>\n",
       "      <td>0.022154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       Bias Type Strategy  Mean PPL BS  Mean PPL OS   t-value   p-value\n",
       "0  BERT  Queerness Bias  Args.me      7.67311     7.393092  2.300889  0.022154"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculatePerplexity('bert-base-uncased', \n",
    "                    df_queerphobia_bias,\n",
    "                    'Queerphobia',\n",
    "                    '/bert_argsme_adapter_cda_sb_all_lbl/checkpoint-46981')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all results\n",
    "pd.DataFrame([all_results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
